{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a93d5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bed1f",
   "metadata": {},
   "source": [
    "## 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c548164",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = pd.read_csv(\"~/aiffel/transformer_chatbot/data/ChatbotData .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e45d67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b31b05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  #sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee78bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡!',\n",
       " '1지망 학교 떨어졌어',\n",
       " '3박4일 놀러가고 싶다',\n",
       " '3박4일 정도 놀러가고 싶다',\n",
       " 'PPL 심하네',\n",
       " 'SD카드 망가졌어',\n",
       " 'SD카드 안돼',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = dialog.Q.to_list()\n",
    "answers = dialog.A.to_list()\n",
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59bb4eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6ae8ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_prep= list(map(preprocess_sentence, questions))\n",
    "answers_prep = list(map(preprocess_sentence, answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab6f8b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡 !',\n",
       " '1지망 학교 떨어졌어',\n",
       " '3박4일 놀러가고 싶다',\n",
       " '3박4일 정도 놀러가고 싶다',\n",
       " 'ppl 심하네',\n",
       " 'sd카드 망가졌어',\n",
       " 'sd카드 안돼',\n",
       " 'sns 맞팔 왜 안하지ㅠㅠ',\n",
       " 'sns 시간낭비인 거 아는데 매일 하는 중',\n",
       " 'sns 시간낭비인데 자꾸 보게됨']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_preped[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba37e69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions_preped[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers_preped[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c31ba7e",
   "metadata": {},
   "source": [
    "##  SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb01c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions_prep + answers_prep, target_vocab_size=2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c61e0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5f73a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8173]\n",
      "END_TOKEN의 번호 : [8174]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac419fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8175\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ef5cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5763, 610, 2492, 4164]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2356, 7513, 7, 6276, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions_prep[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers_prep[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d1a71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "487bde38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8175\n",
      "필터링 후의 질문 샘플 개수: 11568\n",
      "필터링 후의 답변 샘플 개수: 11568\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions_prep, answers_prep)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b6a76",
   "metadata": {},
   "source": [
    "## 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db4de116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d26203a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25dcc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        #print(query.shape)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "        #print(query.shape)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f18d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32) # 0과 같다면 1로 만든다\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :] # 형태가 왜 이럴까?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94336fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9b758e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8de83218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d64d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6b40782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db464e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43367c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a71da2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3147008     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3674368     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8175)   2100975     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,922,351\n",
      "Trainable params: 8,922,351\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "46205f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f3fd6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=1000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5bca85b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "efd995c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef214c96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "181/181 [==============================] - 11s 33ms/step - loss: 3.3825 - accuracy: 0.1141\n",
      "Epoch 2/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 2.5050 - accuracy: 0.1524\n",
      "Epoch 3/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 2.1200 - accuracy: 0.1793\n",
      "Epoch 4/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 1.7104 - accuracy: 0.2176\n",
      "Epoch 5/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 1.3635 - accuracy: 0.2526\n",
      "Epoch 6/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 1.1144 - accuracy: 0.2811\n",
      "Epoch 7/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.8696 - accuracy: 0.3131\n",
      "Epoch 8/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.6531 - accuracy: 0.3470\n",
      "Epoch 9/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.4905 - accuracy: 0.3722\n",
      "Epoch 10/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.3793 - accuracy: 0.3914\n",
      "Epoch 11/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.2945 - accuracy: 0.4065\n",
      "Epoch 12/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.2330 - accuracy: 0.4195\n",
      "Epoch 13/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.1880 - accuracy: 0.4287\n",
      "Epoch 14/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.1547 - accuracy: 0.4366\n",
      "Epoch 15/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.1314 - accuracy: 0.4420\n",
      "Epoch 16/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.1112 - accuracy: 0.4477\n",
      "Epoch 17/20\n",
      "181/181 [==============================] - 6s 33ms/step - loss: 0.0982 - accuracy: 0.4507\n",
      "Epoch 18/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.0861 - accuracy: 0.4541\n",
      "Epoch 19/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.0774 - accuracy: 0.4566\n",
      "Epoch 20/20\n",
      "181/181 [==============================] - 6s 32ms/step - loss: 0.0692 - accuracy: 0.4585\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "92598307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090cabd",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f12a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de405e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "522d18d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 점심 뭐먹지?\n",
      "출력 : 색다른걸 드셔보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'색다른걸 드셔보세요 .'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('점심 뭐먹지?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10fff351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨가 궁금해.\n",
      "출력 : 마음도 추운가요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마음도 추운가요 .'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 날씨가 궁금해.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e638708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 놀러 가고 싶어.\n",
      "출력 : 갈때 저도 같이 가요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'갈때 저도 같이 가요 .'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"놀러 가고 싶어.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e0217dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 취업 하고 싶어.\n",
      "출력 : 합격 기원해요 !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'합격 기원해요 !'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"취업 하고 싶어.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546d1f9",
   "metadata": {},
   "source": [
    "## 회고\n",
    "* 어려웠던점: 트랜스포머 모델 전체 구조를 파악하는것이 어려웠습니다.  \n",
    "  \n",
    "  \n",
    "* 새롭게 알게된 점: 챗봇이 다섯가지 유형으로 나뉘고, 그 중에 대화형 챗봇은 트랜스포머 모델과 Q/A 쌍으로 이루어진 데이터셋으로 만들수 있다는 것을 알게 되었습니다.  \n",
    "  \n",
    "  \n",
    "* 루브릭 지표를 맞추기 위해 한 것: 노드를 참고해서 처음 만든 세팅에서는 학습률 warmup_steps가 4000이였습니다. 한 epoch당 181 스텝을 돌기 때문에 그러면 warmup을 20 epoch 넘게 하게됩니다. 너무 오래 warmup 한다고 생각해서 warmup_steps를 1000으로 낮추었습니다. 그랬더니 정확도가 약 15%에서 45%로 3배 올랐고 적절한 대답을 하는 것을 볼 수 있었습니다.\n",
    "  \n",
    "  \n",
    "* 아쉬웠던점, 다짐: validation set을 만들고 튜닝을 해보고싶었는데 시간 상 안하고 마치게되어서 아쉽습니다. 어렵게 익힌 트랜스포머 모델 안까먹도록 복습 잘 해야겠습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de9221c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
